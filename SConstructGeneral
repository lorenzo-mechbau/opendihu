# SConstruct file to include for a program that uses the opendihu library
#
# In a directory where you have the sources for your user program, place a SConstruct file with the following contents:
##--------------------------------------------------------------------------------------------------------
## import os
##
## # get the directory where opendihu is installed (the top level directory of opendihu)
## opendihu_home = os.environ.get('OPENDIHU_HOME')
## 
## # set path where the "SConscript" file is located (set to current path)
## path_where_to_call_sconscript = Dir('.').srcnode().abspath
## 
## # call general SConstruct that will configure everything and then call SConscript at the given path
## SConscript(os.path.join(opendihu_home,'SConstructGeneral'), 
##            exports={"path": path_where_to_call_sconscript})
##
##--------------------------------------------------------------------------------------------------------
#
import os
import sys
import random

sys.path.append("dependencies/scons-config/dist/scons_config-0.1-py2.7.egg")     # load scons_config

import sconsconfig
from sconsconfig import packages, tools

# import the path where a SConstruct should be called at the end
Import("path")
path_where_to_call_sconscript = path

opendihu_home = Dir('.').srcnode().abspath  # opendihu home directory is where this file is located

#
# Select the packages we want to use in the configuration.
#
sconsconfig.select(
    packages.MPI(required=True),     # This downloads and compiles OpenMPI, but it is recommended to use the system MPI by setting the path in user-variables.scons.py
    packages.LAPACK(required=True),  # This downloads and compiles OpenBLAS which implements the interfaces of both LAPACK and BLAS
    #packages.bison(required=False),   # parser generater needed by PTScotch which is needed by MUMPS which is needed by Petsc
    #packages.flex(required=False),    # "Fast Lexical Analyzer" needed by PTScotch which is needed by MUMPS which is needed by Petsc
    packages.PETSc(required=True),   # Petsc depends on LAPACK/BLAS and bison
    #packages.bzip2(required=False),
    packages.Python(required=True),  # This compiles python 3.6 from source to be able to embedd the python interpreter in opendihu. All further python packages are installed in this installation tree under dependencies/python/install
    #packages.Cython(required=False), # Cython is a dependency for the numpy C API
    #packages.NumpyC(required=False), # The numpy C API. Numpy is needed such that the python config files that are parsed by opendihu can load the numpy package. This needs to be compiled from source and linked to the same LAPACK/BLAS package that also opendihu uses, otherwise there will be errors.
    #packages.SciPy(required=False),  # Scipy to also make it available in the config python files. This just installs from a whl using pip, so no extra compilation.
    #packages.Matplotlib(required=False),   # Matplotlib, again to make it available in the config python files, where you could generate plots in callbacks as the simulation is running. This also installs from a whl using pip, so no extra compilation.
    #packages.NumpySTL(required=False),   # numpy-stl, used for manipulation of stl meshes in fiber test case
    #packages.SvgPath(required=False),   # svg.path python package for manipulating svg paths
    packages.Base64(required=True),  # Base64 is an encoding library that is needed for binary VTK output.
    packages.googletest(required=True),   # This is the testing framework.
    #packages.libxml2(required=True),
    #packages.Sphinx(required=True),
    #packages.libcellml(required=True),          # relies on libxml2 and SWIG
    packages.SEMT(required=True),    # This is a small C++ symbolic differentiation toolbox that is used for solid mechanics.
    packages.EasyLoggingPP(required=True),      # This is the logging library, it has to be the last package to be included because it contains a source (.c) file that needs to be compiled and linked to opendihu and somehow otherwise scons-config does not work.
)

# By default set the packages' location to the dependency directory. This can be overridden in 'user-variables.scons.py'.
# Note that an absolute path has to be given, otherwise there are problems finding the libraries

#preset_variables = {'LAPACK_DIR': os.path.join(opendihu_home, 'dependencies/lapack/install'),
#                    'PETSC_DIR':  os.path.join(opendihu_home, 'dependencies/petsc/install')}


# read variables from user file 'user-variables.scons.py' and from command line arguments, e.g. `scons BUILD_TYPE=release`
variables = ARGUMENTS.copy()        # command line arguments are in the global ARGUMENTS dictionary
#variables.update(preset_variables)  # merge in preset_variables dictionary
vars = Variables(['user-variables.scons.py','../user-variables.scons.py'], variables)

# specify type and default value for recognized variables
vars.Add(EnumVariable('BUILD_TYPE', 'The build type, according to that different compiler options will be set. '\
                      '(Shortcuts: ''d'',''r'',''rd''=''dr'', ''p'')', 'release', 
                      allowed_values=('debug', 'release', 'releasewithdebuginfo', 'preprocess'), ignorecase = 2, 
                      map={'d':'debug', 'r':'release', 'rd':'releasewithdebuginfo', 'dr':'releasewithdebuginfo', 'p':'preprocess'}))
vars.Add(BoolVariable('no_tests', 'Do not compile and run tests.', 0))
vars.Add(BoolVariable('no_examples', 'Do not compile examples.', 0))
vars.Add(BoolVariable('no_examples', 'Do not compile examples.', 0))
vars.Add('cc', help='The c compiler', default='gcc')
vars.Add('CC', help='The c++ compiler', default='g++')
vars.Add('mpiCC', help='The mpic++ compiler wrapper', default='mpic++')
    
# Add options from any packages we want to use.
sconsconfig.add_options(vars)

# initialize environment object containing build system settings such as compilers and flags
# command line options are considered
env = Environment(tools = ['default'], toolpath = ['config/tools'], variables = vars, ENV = os.environ)
vars.Save('out.py',env)

# check for unknown variables and output warning
unknown = vars.UnknownVariables()
if unknown:
  print "WARNING: Unknown variables from command line arguments or config file 'user-variables.scons.py':", unknown.keys()
    
# generate help text for the page `scons -h`
Help(vars.GenerateHelpText(env))

# set console messages for compilation and linking
tty_available = True
try:
  screen = open('/dev/tty', 'w')
except:
  tty_available = False
if ARGUMENTS.get('VERBOSE') != '1' and tty_available:
  env['CXXCOMSTR'] = "\x1b[32mCompiling $SOURCE\x1b[0m"
  env['CCCOMSTR'] = "\x1b[32mCompiling $SOURCE\x1b[0m"
  env['ASCOMSTR'] = "\x1b[32mAssembling $TARGET\x1b[0m"
  env['LINKCOMSTR'] = "\x1b[32mLinking   $TARGET\x1b[0m"
  env['ARCOMSTR'] = "\x1b[36mBuilding archive $TARGET\x1b[0m"
  env['RANLIBCOMSTR'] = "\x1b[36mCreating archive index\x1b[0m"
           
# set compiler, "CC" is C++, "cc" is C
env['CXX'] = env['CC']
env['CC'] = env['cc']

# Create configuration environment, passing the set of custom tests.
sconf = env.Configure(custom_tests=sconsconfig.custom_tests)

# Run custom tests with any options needed.
sconsconfig.check(sconf)

# Finish the configuration and save it to file.
sconf.Finish()

# disable unit tests on hazel hen
if os.environ.get("SITE_PLATFORM_NAME") == "hazelhen":
  env['no_tests'] = True

# -----------------------------------------------
# progress display e.g. [ 50%]

# set needed global variables
env["node_count"] = 0                                         # current counter of nodes to compile
env["node_count_max"] = 0                                     # maximum number of nodes to compile that was determined earlier
env["node_count_interval"] = 1                                # the interval in which the progress output should be updated
node_count_fname = str(env.Dir('#')) + '/.scons_node_count'   # filename of the stored maximum node count
env["node_count_fname"]=node_count_fname

def progress_function(node):
  """ function to be called before a new node is compiled, outputs progress information like [ 50%] if it is <=100%"""
  global env
  env["node_count"] += env["node_count_interval"]
  if env["node_count"] > env["node_count_max"]: env["node_count_max"] = 0
  if env["node_count_max"]>0 and tty_available:
    sys.stdout.write('\r[%3d%%] ' % (env["node_count"]*100/env["node_count_max"]))
    sys.stdout.flush()
  # write out 
  try:
    with open(env["node_count_fname"], 'w') as f: f.write('%d\n' % env["node_count"])
  except: pass

# read in maximum node count from an earlier compilation
try:
  with open(env["node_count_fname"]) as f: env["node_count_max"] = int(f.readline())
except: pass

# add progress display target
Progress(progress_function, interval=env["node_count_interval"])

# add notification when compilation is complete
notify = env.Command(target='notify-send'+str(random.random()), source = None, action = 'notify-send "compilation complete" || true')
AlwaysBuild('notify-send')
    
# -----------------------------------------------
# Depending on the variable BUILD_TYPE either build with debug, releasewithdebuginfo or release settings and link corresponding version of core
# All the flags may only work with the GCC compiler, tested with GCC 5.4.0 and GCC 7.3.0. 
# When using a different compiler that supports C++14, add some 'if's to the next section.

if env["BUILD_TYPE"] == "debug":
  # debug build
  variant_dir = os.path.join(path_where_to_call_sconscript,"build_debug")           # output folder for build
  env.MergeFlags('-ftemplate-backtrace-limit=0 -fstack-check')
  env.MergeFlags('-Werror -Wall -Wno-sign-compare -Wno-error=sign-compare')
  env.MergeFlags('-DDEBUG -ggdb3 -g3 -Og -pg  -DELPP_FEATURE_CRASH_LOG')   # gcc flags, will be sorted automatically into linker and compiler flags
  env.Append(LIBPATH = [os.path.join(opendihu_home, 'core/build_debug')])   # add debug version of opendihu library
  env.Prepend(LIBS = ['opendihud'])
  
elif env["BUILD_TYPE"] == "releasewithdebuginfo":
  # release with debug info build
  variant_dir = os.path.join(path_where_to_call_sconscript,'build_release_with_debug_info')         # folder of build
  env.MergeFlags('-DDEBUG -O2 -ggdb3 -g3 -pg')   # gcc flags, will be sorted automatically into linker and compiler flags
  env.Append(LIBPATH = [os.path.join(opendihu_home, 'core/build_release_with_debug_info')])   # add release with debug info version of opendihu library
  env.Prepend(LIBS = ['opendihurd'])

elif env["BUILD_TYPE"] == "preprocess":
  # only the preprocessing step
  variant_dir = os.path.join(path_where_to_call_sconscript,'preprocess')         # output folder for build
  env.MergeFlags('-DDEBUG -O2 -ggdb3 -g3 -DELPP_DISABLE_DEBUG_LOGS -DELPP_DISABLE_VERBOSE_LOGS -DELPP_DISABLE_TRACE_LOGS -E -C -P ')   # gcc flags, will be sorted automatically into linker and compiler flags
  
else:
  # release build
  variant_dir = os.path.join(path_where_to_call_sconscript,'build_release')         # output folder for build
  env.MergeFlags('-DELPP_DISABLE_DEBUG_LOGS -DELPP_DISABLE_VERBOSE_LOGS -DELPP_DISABLE_TRACE_LOGS -DNDEBUG')
  env.Append(LIBPATH = [os.path.join(opendihu_home, 'core/build_release')])   # add release version of opendihu library
  env.Prepend(LIBS = ['opendihu'])

# flags to always include
env.MergeFlags('-Wunused-variable')   # always warn about unused variables
env.MergeFlags('-std=c++14 -fopenmp -march=native')

# add basic linker flags for linux
env.MergeFlags("-lpthread -ldl -lutil -lm")

# add defines that are used in the code
env.Append(CPPDEFINES = {'-DOPENDIHU_HOME': '\\"'+str(opendihu_home)+'\\"'})   # add define of the directory where this file is located
env.Append(CPPDEFINES = {'-DC_COMPILER_COMMAND': '\\"'+env["CC"]+'\\"'})   # add define of the directory where this file is located

# Set the include path for header files
env.Append(CPPPATH = [os.path.join(opendihu_home, 'core/src')])

#print(env.Dump())

print("Compilers: C: {}, C++: {}, MPI: {}".format(env['CC'],env['CXX'],env['mpiCC']))
# call SConscript file for the actual build in the specified build directory variant_dir
SConscript(dirs=path_where_to_call_sconscript,
           variant_dir=variant_dir,
           duplicate=False,
           exports="env")

